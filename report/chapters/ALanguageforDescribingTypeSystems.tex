\chapter{A Language for Describing Type Systems}


\section{What needs to be described}

In order to build a type checker for the language, the user must have
means to provide the following information:

\begin{itemize}
  \item Types
  \item Language constructs for each type, defining the 'shape' of
    all values of the associate type in weak head normal form
  \item A type-checking rule for each new language construct
  \item Eliminators
  \item Type synthesis rules for each elimination
  \item Beta reduction for each elimination
  \item Optional eta-expansion for each type
\end{itemize}

\section{What is supplied for free}

We provide means to describe a class of languages where all types
exist in a single universe. Although we could allow the user to
provide some name for the universe, we opt not to for simplicity and
instead mandate the construction "set" to mean the universe.

When a user describes types, they are not required to specify that it
is in the universe. In a single universe system there is nowhere else
these constructions could live and so we give this functionality for
free in the resulting software.

\section{The high-level structure of descriptions}

We say that the structure of a description of a type-system is as
follows: 

\begin{itemize}
    \item One or more type descriptions where each is:
      \begin{itemize}
      \item type pattern
      \item premises for determining it is a type
      \item zero or more elimination descriptions where each is:
        \begin{itemize}
        \item eliminator pattern
        \item premises for checking the type of the eliminator
        \item type expression of the whole elimination
        \end{itemize}        
      \item zero or more construction descriptions where each is:
        \begin{itemize}
        \item construction pattern
        \item premises for checking the type of the construction
        \item $\beta$-reduction expression for every elimination described
        \end{itemize}
      \item zero or one $\eta$-expansion rules
      \end{itemize}
\end{itemize}

We place additional conditions on when we are able to supply an
$\eta$-rule which we will discuss further in a future section, however
for now we focus on the important concepts of patterns and expressions
as these are critical to describing and building terms in our DSL.

\section{Representing Patterns}

In the high-level structure we make frequent reference to
patterns. This is a concept we borrow from Conor McBride's previous
work in bi-directional dependent type meta-theory
\cite{TypesWhoSayNi}. These are tools we use to describe when
arbitrary code matches a certain structure.

In order to define a pattern we require meta-level variables to
represent arbitrary subterms in a pattern. We adopt the convention
that meta-level variables are always upper case and so when we speak
of identifiers in this section, we are referring to strings of
uppercase alphabetic characters. Newly bound variables are denoted by
an identifier postfixed with a period, meta-level term variables are
simply an identifier. All meta-level variables must be separated from
the rest of the pattern by whitespace. All other characters are
assumed to be literals and are parsed as atoms except for
parenthesis. We may, for example, describe a pattern representing
lambda terms as follows: 
$$
\mbox{\textbackslash}\;  X. \; ->\; BODY}
$$

Where "\textbackslash" and "-$>$" are interpreted as atoms, "X." is
interpreted as a newly bound variable and "BODY" represents an
arbitrary sub-term. The scope of the newly bound variable is assumed
to extend rightward across the remainder of the term, if this is not
desirable then we may manipulate the structure of the tree with
parenthesis as one might expect, limiting the scope as in the
following example where "X" is not in scope in "ANOTHERSUBTERM". 
$$
\mbox{\textbackslash}\;  (X. \; ->\; BODY) \; and \; ANOTHERSUBTERM}
$$

\section{Representing Expressions}
  
An expression introduces a way for users to build terms from
patterns that we decide are trusted. When we later define the
structure of the DSL in more detail, we will make it clear what
patterns we are allowed to trust in each place where an expression is
required.  \hl{make sure this is done!} This concept is based on the
same meta-theory from which we base our patterns
\cite{TypesWhoSayNi}.

In defining an expression, we define atoms of the expression in
the same way that we did for patterns. We may place multiple elements
side by side separated by whitespace (again in the same way that we
did for our patterns) and use the same encoding for variables, newly
bound variables are encoded with an identifier postfixed with a
period. We may refer to bound variables by giving the appropriate
identifier \emph{prefixed} with a period as in the following example
that constructs the identity function:

$$
\mbox{\textbackslash}\;  X. \; ->\; \{.X\}}
$$

In this case we require that the bound variable reference is
surrounded by curly braces, this is because we are placing a
computation in a place that expects a construction. We will consider
the meaning of this more later and so we do not dwell on it now.
  
Since we require no meta-level sub-expression variables, we assume
that any identifier standing alone and un-post/prefixed is intended to
refer to a meta-level term variable of some pattern that is
in-scope. When this expression is used in some concrete scenario, all
the in-scope patterns will have been matched against terms and these
variable are then used to pull out subterms that we use to construct
the new term. The following example demonstrates the construction of
such an expression when we assume the pattern to the left of the
$\Rightarrow$ is in-scope:

$$
L \; and \; R \Rightarrow \;
\mbox{\textbackslash}\;  X. \; ->\; L \; and \; \{.X\}}
$$

We now consider the case where we refer to a sub-term that exists
under some number of binders in the pattern. If we wish to use such a
term then we must provide the substitution for all of the free
variables in the subterm. It is for this reason that such variables in
an expression can optionally be followed by a "/" and some
substitution. A complete substitution for all free-variables is
mandated in the DSL to avoid unintended variable capture and the
introduction of free variables as in the following case that may occur
if we did not perform this check:

$$
\mbox{\textbackslash}\;  X. \;
\mbox{\textbackslash} \; Y. \; ->\; M} \qquad \Rightarrow \;
  \mbox{\textbackslash}\;  X. \; ->\; \{.X\} \; and\;  M} $$

We must also devise a syntax to describe substitutions themselves,
we do so by simply giving substitutions as a list surrounded by square
brackets, each substitution separated by a comma and is given as an
expression so long as that expression represents a term with a
synthesizable type. When we later talk about how we build our
type-checker we will discuss this further, but for now it is suffice
to explain that we may synthesize the type of a free variable (by
looking up its type in the context) and so if we are to substitute
this variable for another term we should make sure that it is possible
to synthesize its type also incase this is a property that is needed
where the variable was used.

Substutions are given in order according to their de-bruijn index with
the "least local" variable leftmost in the list and the most local
variable rightmost. This list must also begin with a comma. We do not
supply an empty-list in the case that a meta-term-variable cannot
contain free variables, we simply omit it. The following example shows
how we use substitutions in this way by repeating the previous example
except that now we make the captured "X" explicit and remove the free
"Y":

$$
\mbox{\textbackslash}\;  X. \;
\mbox{\textbackslash} \; Y. \; ->\; M} \qquad \Rightarrow \;
  \mbox{\textbackslash}\;  X. \; ->\; .X \; and\;  M/[,\; .X,\; .X]} $$


In the substitution we do not require that the ".X" bound variable
references are surrounded by curly braces, as they are not being
embedded in some construction. So far we have given the various ways
in which we might build expressions that represent constructions and
how we may reference bound variables, how these are computations and
how we might embed a computation in a construction by surrounding it
in curly braces.

There are two other kinds of computations we can encode in our
expressions. We may write an expression representing a term followed
by a colon and another representing its type (both as constructions)
to encode type annotation information or a computation followed by
some whitespace and a construction to encode the elimination of the
computation. 

We give some examples of expressions below giving the in-scope patterns
to the left of the "$\Rightarrow$" separated by commas and the
expression to the right of it. The patterns are only given in this
manner to give context for the benefit of the reader, the
$\Rightarrow$ notation is not part of our DSL.

\begin{align*}
  A \; \times \; B \;\; , \;\; L \; and \; R  \;\; , \;\; \mbox{\textbackslash} \;
  X. \; -> \mbox{\textbackslash} \; Y. \; -> \; M \qquad &\Rightarrow
  \qquad \mbox{\textbackslash} Z. -> M/[,\; (L:A),\; .Z]\\
  TY \;\; , \;\; TM \;\; , \;\; E \qquad &\Rightarrow \qquad
  (TM:TY)\;\; E\\
  A \;\; , \;\; \mbox{\textbackslash} \; X. \; -> M \;\; ,\;\; atm \qquad
  &\Rightarrow \qquad \mbox{\textbackslash} \; X. \; -> ((M/[,\; .X] : A)\;\; atm)
\end{align*}

It is important to note the subtleties in scope when construction
expressions. In the last example, the "X." in the expression does not
shadow the "X." in the pattern, they exist in different scopes. In
fact the "X." in the pattern technically does not exist at all, there
is no way for us to reference it, either in the pattern itself (where
variables do not exist) or in an expression where it is not in
scope. It is merely a mental aid to construction.

\section{Representing premise}

As with patterns and expressions, the concepts of premise and premise
chains that we discuss in this section is heavily influenced by the
same source \cite{TypesWhoSayNi}.

There are four kinds of premise representable in the DSL. Premise are
listed together one after another, chained, in order to give the
conditions under which we may make some judgement. We will first
detail each type of premise before discussing what it means to chain
the premise together and how we determin the scope of a premise. We
will also later detail what is considered in-scope when defining an
expression as part of a premise, and so we gloss over this when
detailing the premises here.

The type premise is written by stating the word "type" followed by
the identifier corresponding to some meta level term variable in
scope.

$$
type \;\; SOMETERM
$$

The type check premise is written as some construction expression,
followed by "\textless -" and some identifier corresponding to a meta
level term variable in scope.

$$
someexpression \;\;<-\;\; SOMETERM
$$

The equivalence premise is written as a construction expression
followed by "=" and another construction expression.

$$
someexpression \;\;=\;\; anotherexpression
$$

The context extension premise is written as some binder identifier,
followed by ":" and a computation expression followed by "$|-$" and
another premise. I.e. it allows to to present an arbitrary premise in
the extended context.

$$
X : someexpression \;\;|-\;\; SOME \;\;<-\;\; OTHERPREMISE
$$

Here we note that the expression must be a computation incase we use
it in some place where type synthesis is required. The context
extension premise is somewhat different in that its use is mandated if
we wish to present a premise talking about some meta-level term
variable that exists under a binder in the original pattern. That is,
we are only allowed to present a term with free variables along with a
context expanded to type them. The name for the free variables is
assigned in the context expansion section of the premise.

A chain of premises is always considered in the context of some
pattern, the subject. A chain of premises also begins with some
trusted pattern, the nature of this pattern depends on were we are
using the chain of premise and will be detailed later. The subject
contains meta-level term variable which we do not yet trust, but seek
to trust, and the trusted pattern contains meta-level term variables
which we trust already. The purpose of a chain of premise is to obtain
trust in the subject by describing how to obtain trust in each of the
meta-level term variables in it. There are two ways that we can
discharge such a variable as trusted: we can state the type of the
term variable with a type check premise, or we can state that the term
variable is a type with the type premise. While we may use context
extension and equivalence checking at will, neither of these premise
discharge anything from what remains to be trusted in the subject.

At the start of a premise chain, only what is initially given as
trusted is in-scope (meaning that we may refer to its meta-level term
variables when building expressions). As we process each link in the
chain, we may potentially move something from the subject (to be
trusted) to the input (which we trust) bringing it in-scope from the
next link in the chain until the end. A chain may only end if there
remains nothing in the subject to be trusted, this is something we
enforce by construction in our software.

The initial scopes of a premise chain, that is the patterns where we
may reference meta term variables without establishing any trust,
differ depending on the purpose for which we are building the
chain. If we are supplying the premises for a new type, then we supply
nothing as initially trusted and the pattern representing the new type
is the subject that we seek to trust. If we are supplying the premises
for checking some language construction is of a certain type, then we
trust that the type as input, and with this information assumed we
seek to trust the new data constructor pattern that we take as a
subject. The type of the target is also in scope when we give the
premises that seek to trust some new eliminator we supply.

\section{$\eta$-expansion rules}

In order for us to perform $\eta$-expansion, there are two pieces of
information that we must have.

Firstly, we must know the top-level data constructor of a newly
$\eta$-expanded term. For this reason, we restrict $\eta$-expansion to
terms which contain only a single data constructor.

Secondly, for each argument to the data constructor, we must know the
eliminator which we might use such that when we eliminate the original
term with the eliminator, we get the term that is supplied as the
argument.

We can therefore give enough information to facilitate
$\eta$-expansion by choosing a pattern representing some value, and
giving an environment for the pattern, where an environment is
structurally identical except that it has a term everywhere the
original pattern had a term variable.

For instance, given the product type $A \; x \; B$ with eliminators
$fst$ and $snd$ which describes values $X , Y$ then we might give $fst
, snd$ to inform the construction of an $\eta$-expansion rule. Similarly,
for a function type $A \; -> \; B$ which describes values $\setminus
X. \; -> \; M$ and is eliminated by some pattern $E$ then we might
give $\setminus Y. \; -> \; Y$ to inform the construction of an
$\eta$-expansion rule which when applied to some target $T$ would
result in an $\eta$-expanded term $\setminus Y. \; -> \; (T \; Y)$.

\section{The DSL}

As previously explained, the top level definition in our DSL
associates a patterns with a type. Every part of the definition
afterward is indented by 2 spaces.

If premises are required (that is to say, if the pattern contains meta
level term variables) then we add an "if:" clause, and then we list
the premises, indented again, on a new line, with each premise on a
line of its own.

We can now show the full structure of describing types in our DSL.

A description of a simple base type with a single value might look as
follows:

\begin{BVerbatim}
  type: alpha
    value: a
\end{BVerbatim}


\section{Determining appropriate eliminations}
\label{appr-elim}

It may seem tempting to enforce certain eliminations. We might have
thought to treat type-parameterised types as assigning a type to each
subterm in a value. For every function, function types assign a type to
the newly bound variable and one to the body, for every pair, product
types assign a type to each element. With this in might we could have
enforced that exactly one eliminator exists for each such
sub-type/sub-term that allows access to this part of the term. This
train of thought seems sensible and initially appears to hold up to
scruitiny.

Following this train of thought further we might consider how we could
deduce $\eta$-expandability from such well-behaved types and
eliminations , however, when we consider sum types then this idea
falters. If we wishted to eta-expand a sum type, how would we know
which constructor to use without peeking at the structure of the
original term? There does not appear to be a way that be might choose
a constructor/eliminator pair that would work to eta-expand an
arbitrary term of the sum type.

As a result, we do not place such restrictions on which eliminators
must exist, and we put the onus on the user to supply enough
information for us to generate the eta-rules where necessary.

\section{Examples}

\section{Good things}

conciseness if needed!

\section{Limitations}

shadowing pattern variables
