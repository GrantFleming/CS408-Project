\chapter{Building a type checker generator}

Now that a user has the means of describing a type system, we will
discuss how the generic type-checking software is constructed.

We will describe key definitions and types to communicate a
high-level understanding of how the software works,
however, we will often omit implementation details in areas where the
code is less important, tedious or verbose.

The general tactic for type-checking some generic syntax will be to
parse the required typing, $\beta$ and $\eta$ rules from the
descriptions provided using our DSL. Using this information we can
then parse user source code and represent it in a fairly
language-agnostic internal object syntax before using the rules
to type-check our internal syntax.

We will begin by describing the internal syntax, talk about how we
might represent the various tools and rules that we need to
type check this syntax and define the type checking process before
briefly covering our approach to parsing this information from the
user-supplied input files. We purposely keep our parsing conversations
brief to prioritize the presentation of challenges in other areas.

Our approach in this section is heavily influenced by the work of
Dr Conor McBride in \emph{The types who say 'ni'} \cite{TypesWhoSayNi}.
Although the code we provide is strictly our own in all cases, there
are some areas where this code is a near-direct translation of
the mathematics in this paper. As we point out in the previous
chapter: patterns, expressions and the treatment of premises are
all concepts that we take from this work. In addition, our internal
syntax is very like that described in the paper and we use the same
approach for thinnings, substitution, contexts and much of our
treatment of scope.

\section{Implementation Overview}

When we provide implementation details in this chapter, we must
provide this information in a ‘bottom-up’ fashion so that the reader
has the required knowledge to makes sense of the later code
examples. To provide context to the reader in the earlier parts of
this chapter we will now provide a high-level description of what we
seek to accomplish. 

Our software operates over an internal syntax that is split into two
grammatical classes, constructions and computations. Constructions
have their types checked, whereas computations have their types
synthesised. The overall aim is to produce two functions, one to check
types and the other to infer types. 

To check and infer types in some arbitrary type system, we need access
to information that describes the system: typing rules, β-rules and
η-rules. These concepts are represented by types in our implementation. 

We will find that these rules are all constructed from the same basic
building blocks. Since we closely follow the approach in \cite{TypesWhoSayNi} then
we require two distinct forms for describing syntax in rules. We
require the ability to match patterns of syntax as information flows
into a rule, and so we provide patterns for this purpose. We also
require the ability to build terms conditionally and define the
information that flows out of a rule and so we define expressions to
accomplish this. These concepts are then used together since
expressions are formed in the presence of some pattern that defines a
trusted input that we may use when building a term. This allows us to
create synthesis rules as functions from input patterns to output
expressions. 

By separating these concerns we can ensure differing characteristics
in each case. Patterns cannot encode computation and further
computation in some term cannot unmatch it from a pattern. In
contrast, we can build computation freely using expressions. 

To finish our rules we require some way to impose conditions on a
pattern so that we might encode the premises of our rules. For this
purpose we provide premises and premise chains, taking care to ensure
that a premise chain is guaranteed to establish a minimum level of
trust in some pattern. 

Since our implementation accepts dependent types, we will need to
provide operational semantics and normalisation (which in turn
necessitates some implementation of substitution). We will need these
concepts to check type equivalence.  

We are explicit in handling scope throughout the project, so before we
describe the implementation of everything we have introduced so far,
we must begin by defining our representation of scope and provide
tools for its manipulation. Using our tools we can create well-scoped
contexts which help to eliminate a large class of potential errors
from the type checking process.

To help visualize the structure of the software, we provide a
high-level dependency graph in figure \ref{fig:dep}. We have arranged
the graph so that the dependencies roughly flow from top to bottom,
and so we will have to implement the software from the bottom up
according to this figure.

\begin{figure}
  \label{fig:dep}
  \caption{The high-level dependency graph}
\centering
\includegraphics[width=\textwidth]{pictures/dependency-graph}
\end{figure}
\clearpage

\input{../../src/latex/CoreLanguage.tex}
\input{../../src/latex/Thinning.tex}
\input{../../src/latex/Substitution.tex}
\input{../../src/latex/TermSubstitution.tex}
\input{../../src/latex/Context.tex}
\input{../../src/latex/Opening.tex}
\input{../../src/latex/Pattern.tex}
\input{../../src/latex/Expression.tex}
\input{../../src/latex/Rules.tex}
\input{../../src/latex/EtaRule.tex}
\input{../../src/latex/Semantics.tex}
\input{../../src/latex/TypeChecker.tex}
\input{../../src/latex/Parser.tex}
\input{../../src/latex/SpecParser.tex}
\input{../../src/latex/LanguageParser.tex}

