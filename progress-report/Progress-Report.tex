\documentclass{ProgressReport}[2020/09/15]

\addbibresource{references.bib}

\title{Type-Checker Generation}
\markingscheme{Software Development Based}
\regnumber{201700435}
\author{Grant G Fleming}
\date{2020/2021}
\supervisor{Conor McBride}

\begin{document}
	\maketitle
	\tableofcontents
        
        \chapter{Aims and Objectives}

        \section{Aim}

        \begin{itemize}
          \item To design, implementation and verify a
            type-checker-generator capabale of generating a
            type-checker given a specification of a type system and a
            grammar of a language. 
        \end{itemize}
        
        \section{Objectives}

        \begin{itemize}
          \item Complete initial readings on type-theory covering
            Simply-Typed Lambda Calculus, System F, Hindley Milner,
            Martin L\"{o}f and bi-directional type-theory along with
            any other identified readings.
          \item Complete specific readings relating to the design and
            implementation of various typesystems and components thereof.
          \item Identify all elements needed to fully and
            unambigiously describe a type system.
          \item Verify sufficiency of identified elements by fully describing
            System F, HM and Martin Lof in this new framework
          \item Formalize a syntax for expressing these elements.
          \item Write a specification of a type-checker-generator.
          \item Design a type-checker-generator.
          \item Implement a type-checker-generator.
          \item Verify the implementation according to the
            specification.
          \item Evaluate the DSL and identify any limitations on the
            kind of type systems that it can represent.
        \end{itemize}
        
        \chapter{Related Work}

          Type systems, as with so many concepts in computer science,
          were born from the primordial soup that is the study of
          logic. The initial purpose of type systems was to resolve
          certain inconsistencies in an underlying logic. 
      
          Although originally proposed by Bertrand Russell in 1902 to
          resolve a paradox he himself had discovered in a formalization of
          Gottlob Frege's naive set theory in 1901 \cite{Russell1901}, much
          introductory material on type theory begins the story with
          Alonzo Church and his simply typed lambda calculus
          \cite{church1940}.
      
          Like Russell, Church was searching for a way to make his
          previously define system of logic, the lambda calculus,
          consistent. In 1940 he published his seminal paper that outlined a
          type system and added an extra layer of contraint to his
          previously defined system. Now, a term in lambda calclus is well
          formed if and only if it is typeable.
      
          A concrete, if informal, summation of Church's work here is that
          in this new system, if a lambda abstraction is applied to a term,
          the type of the term must be the same type as the binder in the
          abstraction. As a consequence, previously well formed terms which
          caused inconsitencies in the logic, such as
          $ (\lambda x.xx)(\lambda x.xx)  $
          were no longer well formed under the new system.
      
          The importance of this particular work is due to it's influence in
          the early years of programming language design that began around
          the 1950s and exploded in the 1960s. In fact, it turned out
          that this calculus could be used as what we would now
          recognise as a Turing-complete model of computation. This
          facilitated its use as a programming language where the type
          system he later imposed on it would aid programmers in
          avoiding certain classes of errors. 
      
          As the field of computer science developed in sophistication in
          the late 1960s and 1970s, the great minds of the era were hard at
          work on the next big development in type systems: parametric
          polymorphism. It was noted that some functions had common
          behaviour over differing types, and that the behaviour of these
          functions did not depend on the types themselves. This lead to
          redudent definitions such as having to define a function with the
          same behaviour multiple times, once for each type you wish to
          operate over. Under type systems akin to the simply typed lambda
          calculus, the id function given by the term $\lambda
          x_{\mathbb{N}}.x $ is only ever applicable to natural numbers. It
          is clear that there was immense benefit in being able to define
          functions such as id once and have them operate over any type.
      
          One such solution to this problem came to be known as System F
          or polymorphic lambda calculus. This system was independently
          discovered by Jean-Yves Girard and John Reynolds in 1972 and 1974
          respectively \cite{Girard1972,reynolds1974}.
      
          In lambda calculus, a single binder $\lambda$ is used to bind variables
          that range over values. In the simply typed lambda calculus, a
          lambda term of the form $\lambda x_{\alpha}.M_{\beta}$ (where
          $x_{\alpha}$ binds variables $x$ over a type $\alpha$ and
          $M_{\beta}$ is some term of type $\beta $) has type
          $\alpha\to\beta$ by modern notation. System F introduces a new
          binder $\Lambda$ that is used to bind variables that range over
          types. In this system, terms of the form $\Lambda t.M$ denotes a
          function that takes as its first argument some type and returns a
          term with all references to t replaced by that type. This function
          has type $\Delta t.M^{t}$ where $M^t$ is is the type of $M$.
      
          Under this system, we may write the id function as $\Lambda t
          . \lambda x_t . x$ and thus have it operate over any type t,
          so long as we supply it.
      
          One limitation of this system is the lack of shades of typing
          grey. There are only two states in this model of polymorphism:
          either a type variable has not been supplied to a binder,
          and thus can potentially take on any type, or the bound type
          variable is fully binded to a specific concrete type then the
          function is used at exactly that type. It can also be noted that under
          this system we are required to supply the type of the binder in
          every $\lambda$ expression, this could get quite tiresome. Perhaps
          there is use for some shades of grey in our type system, and do we
          really need to type our $\lambda$ binders?

          \section{Hindley-Milner}

            Work on what we now refer to as the "Hindley-Milner" type system began
            in the late 60s and grew to become the basis of many functional
            languages such as ML and Haskell.
            
            This system, like System F, incorporates parametric polymorphism as a
            first class feature. It does, however, deal with the gory details of
            its formalization in a very different way, allowing it to glean some
            desirable properties that System F cannot claim.
            
            Firstly, when we define polymorphic functions, we need not explictly
            bind the type variables, and thus when we use them, we need not
            explicitly provide a type parameter. Instead, Hindley introduces a
            system of \textit{type-schemes} \cite{hindley1969} (types
            that may contain quantified type variables) and defines a
            type as being a type-scheme that contains no type
            variables. Milner refers to these concepts as polytypes
            and monotypes respectively \cite{milner1978}.
            
            This has the consequence that a given term may have any number of
            type-schemes, some more general than others, some more specific
            allowing us some 'shades of grey' in our type system and allowing us
            to commit to stating more or less about our values as the situation
            requires. Hindley then presents the idea of a \textit{principle type
              scheme} (p.t.s) or the most general polytype, where all possible
            types for a given term are instances of the p.t.s. Consequently any
            type-scheme of a term can be created by performing some consistent
            substitution for the type variables in the p.t.s. 
            
            He then proves that any term for which you can deduce a type scheme,
            has a p.t.s. and it is always possible to work out what the p.t.s. is
            up to \textit{trivial instances} - instances that are equal up to the
            consistent renaming of type variables.
            
            The idea of being able to always infer the most general type of an
            expression is a defining feature of this type system. Let us take a
            moment to ponder the ramifications of this feature.
            
            \subsection{Type Annotations}
            
            In Hindley-Milner, there is no need for us to annotate the definitions
            in our code with type information.
            
            Since we can always infer the p.t.s (most general type-scheme) of
            expressions we, as programmers, need not supply this type information
            in code when we make our definitions. This can result in cleaner
            looking code in some circumstances however there is an argument that
            providing type information explicitly in the syntax of the language
            serves as important documentation.
            
            \subsection{Type Checking}
            
            The type inference algorithm that is detailed in the Hindley-Milner
            system is instrumental in the way types are checked.
            
            In a system like System F, whenever we wish to apply a polymorphic
            function, we must provide the type parameter first before providing
            the value parameter so that we may type-check the provided value
            parameter. With Hindley-Milner, as a direct consequence of its type
            inference features, this is not necessary. Instead we can infer the
            most general type of the function, and check that the supplied
            argument is some instance of the functions input type. This is
            generally regarded as a good thing, less we end up with code that
            contains so much type information as to be rendered unreadable.
            
            The classic example of such systems is the creation of lists in the
            standard $cons/[]$ way. In a language with a type system akin to
            System F, this may look
            something like:
            
            \begin{minted}{haskell}
              (cons Number 1 (cons Number 9 (cons Number 6 [])))  
            \end{minted}
            
            whereas if we can infer the most general type of $cons$ and
            subsequently verify that the supplied input is some instance of this
            type as in Hindley-Milner, the same expression might be written as:
            
            \begin{minted}{haskell}
              (cons 1 (cons 9 (cons 6 [])))  
            \end{minted}
            
            We can see this difference reflected in the typing rules of the
            systems by way of the following example on id:
            
            \[\begin{array}{c@{\qquad}|@{\qquad}c}
                  \mbox{Hindley-Milner}
                  &
                  \mbox{System F}
                  \\\\
                  id : \forall \alpha \cdot \alpha \to \alpha
                  &
                  id : \Delta \alpha \cdot \alpha \to \alpha
                  \\\\
                  id = \lambda x \cdot x
                  &
                  id = \Lambda t . \lambda x_t \cdot x
            \end{array} \]
            
            The type in the Hindley-Milner system can be proven by:
            
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                    \hypo{x : \alpha \in x : \alpha}   
                  \infer1[var]{x : \alpha \vdash x : \alpha}
                \infer1[abs]{\vdash \lambda x \cdot x : \alpha \to \alpha}
                \hypo{\alpha \notin free(\epsilon)}
               \infer2[gen]{\vdash \lambda x \cdot x : \forall \alpha \cdot
               \alpha \to \alpha}
            \end{prooftree}}
            \end{array} \]
            
            
            The equivalent type in System F can be proven by:
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                  \hypo{x : \alpha \in x : \alpha}
                \infer1[var]{x : \alpha \vdash x : \alpha}
               \infer1[abs]{\vdash \lambda x_t \cdot x : \alpha \to \alpha}
               \infer1[$\Delta$-abs]{\vdash \Lambda t . \lambda x_t \cdot
                 x : \Delta \alpha \cdot \alpha \to \alpha}
            \end{prooftree}}
            \end{array} \]
            
            In system F, this deduces the only type for $\Lambda t . \lambda x_t
            \cdot x$ (up to the renaming of bound variables) however note that
            because of the 'shades of grey' allowable as a result of type
            specialization and generalization in Hindley-Milner we may
            also deduce other type (schemes) for $\lambda x \cdot x$:
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                        \hypo{x : \alpha \to \beta \in x : \alpha \to \beta}
                    \infer1[var]{x : \alpha \to \beta \vdash x : \alpha \to \beta}   
                    \infer1[abs]{\vdash \lambda x \cdot x : (\alpha \to \beta) \to
                    (\alpha \to \beta)}
                    \hypo{\beta \notin free(\epsilon)}        
                \infer2[gen]{\vdash \lambda x \cdot x : \forall \beta \cdot
                  (\alpha \to \beta) \to (\alpha \to \beta)}
                \hypo{\alpha \notin free(\epsilon)}
               \infer2[gen]{\vdash \lambda x \cdot x : \forall \alpha . \forall
                 \beta \cdot (\alpha \to \beta) \to (\alpha \to \beta)}
            \end{prooftree}}
            \end{array} \]
            
            Where $\forall \alpha . \forall \beta \cdot
            (\alpha \to \beta) \to (\alpha \to \beta) \sqsubseteq \forall \alpha \cdot
               \alpha \to \alpha$ (meaning that $\forall \alpha . \forall \beta \cdot
            (\alpha \to \beta) \to (\alpha \to \beta)$ can be derived
               from $\forall \alpha \cdot \alpha \to \alpha$ by
               consistenfly substituting for $\alpha$ in its body.
            
            If you wanted a term with an equivalent type in system F you would
            need to create a new term $\Lambda t_1 . \Lambda t_2 . \lambda x_{t_1
              \to t_2} \cdot x$
            
            A full list of the typing rules for System F and Hindley-Milner are
            available in appendices \ref{appendix:sysFrules} and
            \ref{appendix:HMrules} respectively.
                    
          \section{Martin L\"{o}f}
            
          \section{Further planned related work exploration}
        
        \chapter{Project Specification}
        \chapter{Project Plan}

        \chapter{Summary of Proposals}
        \section{Development Methodology}
        \section{Design}
        \section{Implementation}
        \section{Testing}
        \section{Evaluation}
	
	\input{appendices.tex}
	
	\clearpage
	\addcontentsline{toc}{chapter}{Bibliography}
	\printbibliography
	\nocite{*} % temporarily until I know what I'm using
\end{document}
