\chapter{A Language for Describing Type Systems}

In order for a user to provide the necessary input so that the
software can generate the required type-checker, it is necessary that
they are able describe the type-system. In this chapter, we will
introduce a domain specific language (DSL) that can be used to write
type-system specifications for our generator.

There are several elements that need defining: Types, Terms Semantics
and Typing Rules. In the specification file, each of these sections is
denoted by appearing, prefixed by a '\#' and a space on a line of its
own (\# types, \# terms etc). The beginning of a new section ends the
previous section and the sections must appear in the following order:

\begin{enumerate}
  \item \# types
  \item \# terms
  \item \# semantics
  \item \# rules
\end{enumerate}

The '\# semantics' section may be optionally omitted \hl{until
  dependent types are needed? until term equivalence?}. In the
specification file, lines beginning with '- -' identify comments and
are ignored.

Complete example specifications files are available in appendix
\ref{appendix:examplespecifications}

\section{Specifying A Grammar}

We specify a general structure of a grammar, but we leave key elements
to be specified by the user. We require a user to describe two aspects
of the language: types and terms. For the time being, these constructs
are treated seperately.

\subsection{Types}

A specification of the types begins with the string '\# types' on
a line of its own.

We make a distinction between types and type constructors, the user
must supply any of each they wish to be part of their type system, at
a minimum, a single base type with values is expected.

Type definitions are optionally supplied in pairs along with
their values, supplying values here allows users to specify base
types. If a user chooses to include values in their type definition
then the values are automatically included as inferrable terms in the
grammar and a type inference rule is generated for each value provided.

Base types are given names that identify them and values separated by
a whitespace. A 'values' declaration following a 'base'
declaration associates the values with the type but is not mandatory,
it is possible to supply the type name only and define the values later
using typing rules.

An example of a base type definition is that of the booleans:

\begin{verbatim}
type   Bool
values True False
\end{verbatim}

Type constructors are defined as a series of tokens and whitespace
where arguments are denoted by '@' as in the following examples:

\begin{verbatim}
constructor  @ -> @
constructor  @ + @
constructor  Maybe @
\end{verbatim}


\subsection{Terms}

A specification of terms begins with the string '$\# \; terms$' on a
line of its own.

A user can visualise the following snippet of grammar describing terms:

\begin{align*}
<\mbox{check}> &::= <\mbox{infer}> | ... \\
<\mbox{infer}> &::= <\mbox{var}> | ...
\end{align*}

where they must fill in the ellipses. We specify two main classes of
terms, that for which the type is synthesizable $<\mbox{infer}>$, and
that for which the type is checkable $<\mbox{check}>$. All synthesizable
terms are checkable (if we wish to check the type, we merely
synthesize the type then check if it matches the given type we are
checking against). A user need not fill in grammar definitions for
both $<\mbox{check}>$ and $<\mbox{infer}>$, it is possible to define
some languages with one or the other. It is not necessary to specify
$<\mbox{check}> ::= <\mbox{infer}>$ or
$<\mbox{infer}> ::= <\mbox{var}>$, this is handled implicitly.

To allow for type annotation, the non-terminal symbol $<\mbox{type}>$
is allowed when specifying the grammar of terms although definitions
such as $<\mbox{infer}> <\mbox{check}> ::= <\mbox{type}>$ are not
\hl{(expand later)}.

The definition: $<\mbox{infer}> ::= <\mbox{check}>$ is not allowed.

\section{Operational Semantics}

\hl{When we later come back to include dependent types, it will become
necessary to define a syntax for describing operational semantics
here. We may also think about the benefits of reducing terms to
head-normal form and the implications of this.}

\section{Typing Rules}

\subsection{An Overview of Typing Rules as a Concept}

Typing rules require \emph{judgement forms}. These describe the nature
of statements we are allowed to make when we build the rules. The
number of judgement forms varies between type-systems, although there
are similar forms used in nearly all such systems.

Simple type-systems may be represented with just a single judgement
form:
$$\boxed{\Gamma \vdash x : \tau}$$
Stating that in a given context $\Gamma$ the syntactic entity
$x$ has type $\tau$. More sophisticated type-systems often need to be
able to make statements other than just stating a type. For instance,
in Martin L\"of type theory, as well as having a judgement for to make
statements about the types of values, we can also make statements
about what is considered a type, the equivalence of types, and the
equivalence of values under a type:
$$\boxed{\tau \; \mbox{Set}} \qquad \boxed{\sigma = \tau} \qquad \boxed{x = y
  \in \tau}$$

Judgement forms are then used to make \emph{judgements} which are
combined to create \emph{typing rules}. These typing rules make up the
core meaning of a type system. Their primary purpose is to describe
when an entity can be said to have a particular type associated with
it. For example, in the Simply Typed Lambda Calculus, the following
rule describes how a type is associated with a lambda abstraction:

$$\boxed{
\mbox{\begin {prooftree}
  \hypo{\Gamma , x : \sigma \vdash t : \tau}
  \infer1[]{\Gamma \vdash \lambda x : \sigma . t : \sigma \to \tau}
\end {prooftree}}
}$$


The judgments that are combined to form this rule have already been
discussed, however in place of the variables that existed in the
judgement forms there are now various language constructs.

$\lambda x . t$ is clearly a lambda abstraction, but it is also worth
noting that in this rule, it is not a specific abstraction. We must be
careful to note that $x$ is a placeholder for an arbirary binder and
$t$ for an arbitrary body. There are also type-variables $\sigma$ and
$\tau$ that exist at this meta level. $\Gamma$ stands for an arbitrary
context and $\vdash$ is a concrete symbol of syntax at meta
level. $\lambda$ , $.$ and $\to$ are concrete syntax of the
language. Greate care must be taken

\subsection{Typing Rules in the DSL}

A specification of the typing rules begins with the string '\# rules'
on a line of it's own.

Our approach is based on a formalization of bi-directional type-theory
\cite{TypesWhoSayNi} hl{( <- is it?) and so we begin our first iteration by providing
just three judgement forms, the first two judgement forms are for
synthesizing and checking types respectively:

$$\boxed{\Gamma \vdash s \in \sigma} \qquad \boxed{\Gamma \vdash \sigma
  \ni t}$$

In these definitions, s must be some synthesizable term, t can be any
term, and $\sigma$ is some type.

The third judgement allows us to make statements about equivalence of
types:

$$\boxed{\sigma \equiv \tau}$$

\hl{In our current iteration, this judgement does not rely on a
  context and we later specify a rule which states that types are
  equivalent iff the are exactly the same.}

\subsubsection{A Syntax for Judgements}

When we create judgements from judgement forms, it is helpful to
be specific about exactly what is a meta-level variable, so we specify
that meta-level term variables be surrounded in \{\}, meta-level type
variables in [] and meta-level variable variables (yikes!) are
quoted (as in the meta variable 'x'). It is important to make these
distinctions so that we know, for instance, that an arbitrary term
does not end up in the context, or to ensure that a meta-level
variable variable is not used where a meta-level type variable is
expected. Creating these distiction in meta level variables also helps
us later in validating judgements against with regards to the syntax
of the language.

We follow a convention of not mentioning the context unless we are
being explicit about it being extended in some way, and even then only
mentioning the extension. Extensions, as they are used in specifying
typing rules, are comma separated lists of entries assigning types (or
meta-level type variables) to meta-level variable variables: 

\begin{verbatim}
'x' : [s] , 'y' : Bool , ...
\end{verbatim}

The context is separated from the rest of the judgement by a vertical
bar, and the characters $\in$ and $\ni$ are encoded as $<<$ and $>>$
respectively.

The part of the judgement that specifies the type is surrounded by
parenthesis, this allows for a clear switch of context when parsing, we
may using $>>$, $<<$ or $\vert$ as type constructors or language constructs if
we wish. The part specifying the term is also surrounded in standard
parenthesis for the same reason.

For example, the judgement:
$$\Gamma, y : \sigma \to \sigma \vdash \sigma \to \sigma \ni \lambda x
. y x$$
is written in our specification file as:
\begin{center}
\begin{BVerbatim}
'y' : [s] -> [s] | ( [s] -> [s] ) >> ( \ 'x' . 'y' 'x' )
\end{BVerbatim}
\end{center}

Care must to taken when making judgements to ensure that synthesizable
judgements are made on synthesizable terms only.

\subsubsection{A Syntax for Rules}

Typing rules are defined as follows:
\begin{itemize}
  \item Each typing rule starts with a line denoted by two or more '='
    characters in a row and nothing else except whitespace
  \item The premise come first, each judgement on a line on its own
  \item a line of two or more '-' characters separate the premise from
    the conclusion
  \item The conclusion judgement appears on a line by itself
  \item The typing rule end is denoted by a line with two or more '='
    characters in a row and nothing else except whitespace
\end{itemize}

For example, a rule:

$$\boxed{
\mbox{\begin {prooftree}
    \hypo{\Gamma \vdash f \in \sigma \to \tau}
    \hypo{\Gamma \vdash \sigma \ni x}
  \infer2[]{\Gamma \vdash f x \in \tau}
\end {prooftree}}
}$$

may be denoted in our syntax as:

\begin{center}
\begin{BVerbatim}
=====================================
| ( {f}     ) << ( [sigma] -> [tau] )
| ( [sigma] ) >> ( {x} )
-------------------------------------
| ( {f} {x} ) << ( [tau] )
=====================================
\end{BVerbatim}
\end{center}

and a rule:

$$\boxed{
\mbox{\begin {prooftree}
  \hypo{\Gamma , x : \sigma \vdash \tau \ni t }
  \infer1[]{\Gamma \vdash \sigma \to \tau \ni \lambda x . t}
\end {prooftree}}
}$$

may be denoted:

\begin{center}
\begin{BVerbatim}
=========================================
'x' : [sigma] | ( [tau] ) >> ( {t} )
-----------------------------------------
| ( [sigma] -> [tau] ) >> ( \ 'x' . {t} )
=========================================
\end{BVerbatim}
\end{center}

\subsubsection{Typing Rule Validation}

Care must be taken to understand the scope of meta variables in the
typing rules, the rules are read differently depending on the choice
of judgement in the conclusion and this can affect when meta-variable
usage indicates a binding site or a reference. Here, we take a (well scoped)
reference as referring to a value bound at a binding site within the
same rule, and a binding site as binding a value given to the rule
from something external. 

There are four cases that have to be handled seperately and define
whither meta variables are binding sites or references, these cases
depend on whither the judgement is a checking or synthesis judgement:

$$\mbox{check: }\textbf{\emph{context}} \; \vert \; \textbf{\emph{type}}
>> \textbf{\emph{term}}$$
$$\mbox{ infer: }\;\textbf{\emph{context}} \; \vert \; \textbf{\emph{term}}
<< \textbf{\emph{type}}$$

and whither the judgement is used as the conclusion of a rule, or as a
premise. All meta variable variables that appear in 
\textbf{\emph{context}} are references however meta type variables may
be either references or binding sites.

\begin{table}[h!]
\centering
\begin{tabular}{|l|p{16em}|p{16em}|}
  \hline
             \begin{tabular}{l}
               judgement $\to$ \\
               location $\downarrow$
             \end{tabular}
           & check
           & infer  \\ \hline
conclusion & \begin{tabular}{p{15em}}
             All meta variables in \textbf{\emph{type}} are
             binding sites. \\
             All meta variables in \textbf{\emph{term}} are
             binding sites.
             \end{tabular}
           & \begin{tabular}{p{15em}}
             All meta variables in \textbf{\emph{type}} are
             references. \\
             All meta variables in \textbf{\emph{term}} are
             binding sites.
             \end{tabular}
           \\ \hline
premise    & \begin{tabular}{p{15em}}
             All meta variables in \textbf{\emph{type}} are
             references. \\
             All meta variables in \textbf{\emph{term}} are
             references.
             \end{tabular}
           & \begin{tabular}{p{15em}}
             All meta variables in \textbf{\emph{type}} are
             binding sites. \\
             All meta variables in \textbf{\emph{term}} are
             references.
             \end{tabular}
           \\ \hline
\end{tabular}
\end{table}

Meta-variable scope is defined simply: after a meta variable
binding has been read, it is in scope for the rest of the reading of
the rule. However, the way in which rules are read is non-obvious.

Where the conclusion is a checking judgement, we start with the
conclusion and read:

$$\mbox{\textbf{\emph{term}}} \to \mbox{\textbf{\emph{context}}} \to
\textbf{\emph{type}} \to \mbox{\textbf{\emph{premise
      top-to-bottom}}}$$

and where it is a synthesis judgment we start and end with the
conclusion reading:

$$\mbox{\textbf{\emph{term}}} \to \textbf{\emph{context}} \to
\mbox{\textbf{\emph{premise top-to-bottom}}} \to
\mbox{\textbf{\emph{type}}}$$ 

To ensure proper scoping, we also need to impose some order on the reading of
each premise depending on judgement form. Checking judgements may only
contain references and so the order of reading does not matter,
however in synthesis judgement we have to be sure that meta type
variables bound in \textbf{\emph{type}} are not in-scope in
\textbf{\emph{context}} and so we enforce the reading order:

$$\mbox{\textbf{\emph{term}}} \to \mbox{\textbf{\emph{context}}} \to \mbox{\textbf{\emph{type}}}$$

For simplicity we read checking judgements in the same order.

\subsection{A Summary of Free Rules}

There are various rules that are provided automatically and need not
be defined. We have introduced some of these rules already but for
convenience they are all specified here.

Firstly, if the user has chosen to specify values for a base type when
they defined it, for each value $c$ of base type $\tau$ a constant
rule exists, not a single rule for typing constants, but a seperate
rule per constant. A rule for synthesizing variable types is also
provided as well as a rule for embedding synthesizable judgements as
checkable judgements.

$$
\boxed{
\mbox{\begin {prooftree}
  \infer0[const]{\Gamma \vdash c \in \tau}
\end {prooftree}}
}
\qquad
\boxed{
  \mbox{\begin {prooftree}
  \hypo{v \notin \Gamma '}    
  \infer1[var]{\Gamma , v : \tau , \Gamma ' \vdash v \in \tau}
  \end {prooftree}}
}
\qquad
\boxed{
  \mbox{\begin {prooftree}
  \hypo{\Gamma \vdash t \in \sigma}
  \hypo{\sigma \equiv \tau}
  \infer2[chk]{\Gamma \vdash \tau \ni t}
\end {prooftree}}  
}
\qquad
\boxed{
  \mbox{\begin {prooftree}
  \hypo{\sigma = \tau}
  \infer1[type-eqv]{\sigma \equiv \tau}
\end {prooftree}}  
}
$$

The 'chk' rule may need revisited if we introduce type schemes. These
rules may use judgements not available to the user.

\hl{At the time of writing, our notion of type equivalence is
  basic. Two types are equivalent $\sigma \equiv \tau$ if and only if they
  are exactly the same type $\sigma = \tau$. In practice this
  means that they are either the same base type, or they are the same
  type constructor with equivalent arguments.}

\section{NOTEPAD}

At the moment, we do not allow $<\mbox{check}> ::= <\mbox{type}>$ and
we do not allow terms as arguments to type constructors. Dependent
types will be revisited later.

Go back and see if we can work in types to the constructors.

Most of this work only discusses two type constructors, it will need
expanded.

Will we enforce restrictions on the type systems? Will we check for
stability under substitution or subject reduction?

Will we check operational semantics? What about checking that a
language is strongly normalizing?

\cite{TypesWhoSayNi} page 6 introduces \emph{expressions} in rules as
well as specifying the benifits of being specific about information
flow in the rules the way we have.
