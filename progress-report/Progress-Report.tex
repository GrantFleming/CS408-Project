\documentclass{ProgressReport}[2020/09/15]

\addbibresource{references.bib}

\renewcommand{\arraystretch}{1.7}

\title{Type-Checker Generation}
\markingscheme{Software Development Based}
\regnumber{201700435}
\author{Grant G Fleming}
\date{2020/2021}
\supervisor{Conor McBride}

\begin{document}

        \maketitle
	\tableofcontents
        
        \chapter{Aims and Objectives}

        \section{Aim}

        \begin{itemize}
          \item To design, implementation and verify a
            type-checker-generator capable of generating a
            type-checker given a specification of a type system and a
            grammar of a language. 
        \end{itemize}
        
        \section{Objectives}

        \begin{itemize}
          \item Complete initial readings on type-theory covering
            Simply-Typed Lambda Calculus, System F, Hindley Milner,
            Martin L\"{o}f and bi-directional type-theory along with
            any other identified readings.
          \item Complete specific readings relating to the design and
            implementation of various typesystems and components thereof.
          \item Identify all elements needed to fully and
            unambiguously describe a type system and unify them under
            a common framework.
          \item Verify sufficiency of identified elements by fully describing
            two different type systems in the framework.
          \item Formalize a syntax for expressing these elements.
          \item Write a specification of a type-checker-generator
            including identifying areas for verification and/or
            testing. 
          \item Design and implement a type-checker-generator.*
          \item Verify the implementation according to the
            specification.
          \item Evaluate the DSL and identify any limitations on the
            kind of type systems that it can represent.
        \end{itemize}

        * The design and implementation sections have been combined
        here as this phase will be conducted in an agile manner via
        scrum-style sprints.
        
        \chapter{Related Work}

        \section{Background, Lambda Calculus and System F}

          Type systems, as with so many concepts in computer science,
          are a concept borrowed from the study of logic; their initial
          purpose was to resolve certain inconsistencies in an
          underlying logic. 
      
          Although originally proposed by Bertrand Russell in 1902 to
          resolve a paradox he himself had discovered in a formalization of
          Gottlob Frege's naive set theory in 1901 \cite{Russell1901}, much
          introductory material on type theory from a computer science
          perspective begins with Alonzo Church and his simply typed
          lambda calculus \cite{church1940}.
          
          Like Russell, Church was searching for a way to make his
          previously define system of logic, the lambda calculus,
          consistent. In 1940 he published his seminal paper that outlined a
          type system and added extra criteria to which a term must
          conform in order to be considered well-formed - it must be typeable.
      
          A concrete, if informal, summation of Church's work here is that
          in this new system, if a lambda abstraction is applied to a term,
          the type of the term must be the same type as the binder in the
          abstraction. As a consequence, previously well formed terms which
          caused inconsistencies in the logic, such as
          $ (\lambda x.xx)(\lambda x.xx)  $
          were no longer well formed under the new system.
      
          As the field of computer science developed in sophistication in
          the late 1960s and 1970s, prominent logicians and computer
          scientists started to develop the notion of parametric
          polymorphism. It was noted that some functions had common
          behaviour over differing types, and that the behaviour of these
          functions did not depend on the types themselves. This lead to
          redundant definitions such as having to define a function with the
          same behaviour multiple times, once for each type you wish to
          operate over. Under type systems akin to the simply typed lambda
          calculus, the \emph{id} function given by the term $\lambda
          x_{\mathbb{N}}.x $ is only ever applicable to natural numbers. It
          is clear that there was immense benefit in being able to define
          functions such as \emph{id} once and have them operate over any type.
      
          One such solution to this problem came to be known as System F
          or polymorphic lambda calculus. This system was independently
          discovered by Jean-Yves Girard and John Reynolds in 1972 and 1974
          respectively \cite{Girard1972,reynolds1974}.
      
          In lambda calculus, a single binder $\lambda$ is used to bind variables
          that range over values. In the simply typed lambda calculus, a
          lambda term of the form $\lambda x_{\alpha}.M_{\beta}$ (where
          $x_{\alpha}$ binds variables $x$ over a type $\alpha$ and
          $M_{\beta}$ is some term of type $\beta $) has type
          $\alpha\to\beta$ by modern notation. System F introduces a new
          binder $\Lambda$ that is used to bind variables that range over
          types. In this system, terms of the form $\Lambda t.M$ denotes a
          function that takes as its first argument some type and returns a
          term with all references to t replaced by that type. This function
          has type $\Delta t.M^{t}$ where $M^t$ is is the type of $M$.
      
          Under this system, we may write the \emph{id} function as $\Lambda t
          . \lambda x_t . x$ and thus have it operate over any type t,
          so long as we supply it.
      
          One disadvantage of this system is that terms become verbose
          because of their explicit references to type
          information. Another is that explicit quantification over
          types can quickly become unwieldy when writing more complex
          types for polymorphic functions.

          \section{Hindley-Milner}
            An alternative approach to parametric polymorphism was
            developed in the late 60s with the Hindley-Milner type
            system which grew to become the basis of many functional
            languages such as ML and Haskell.
                        
            Hindley introduces a system of \textit{type-schemes}
            \cite{hindley1969} (types that may contain quantified type
            variables) and defines a type as being a type-scheme that
            contains no such variables. Milner refers to these
            concepts as polytypes and monotypes respectively
            \cite{milner1978}. 
            
            This has the consequence that a given term may have any number of
            type-schemes, some more general than others, some more specific
            allowing us to commit to stating more or less about our
            values as the situation requires. Hindley then presents
            the idea of a \textit{principle type scheme} (p.t.s) where
            all possible type-schemes for a given term are instances
            of the p.t.s. (that is, can be constructed by consistent
            substitution for quantified variables in the p.t.s.).
            
            He then proves that any term for which you can deduce a type scheme,
            has a p.t.s., that it is always possible to work out what the p.t.s. is
            up to \textit{trivial instances} and introduces an
            algorithm to accomplish this type inference - Algorithm W.

            As a consequence of this system there is no need for us to
            annotate the definitions in our code with type
            information since we can always infer the p.t.s (most
            general type-scheme) of our terms. This can result
            in cleaner looking code in some circumstances however
            there is an argument that providing type information
            explicitly in the syntax of the language serves as
            important documentation.
            
            The type inference algorithm that is detailed in the Hindley-Milner
            system is also instrumental in the way types are checked.
            
            In a system like System F, whenever we wish to apply a polymorphic
            function, we must provide the type parameter first before providing
            the value parameter so that we may type-check the provided value
            parameter. With Hindley-Milner, as a direct consequence of its type
            inference features, this is not necessary. Instead we can infer the
            most general type of the function, and check that the supplied
            argument is some instance of the functions input type.
            
            The classic example of such systems is the creation of lists in the
            standard $cons/[]$ way. In a language with a type system akin to
            System F, this may look
            something like:
            
            \begin{minted}{haskell}
              (cons Number 1 (cons Number 9 (cons Number 6 [])))  
            \end{minted}
            
            whereas if we can infer the most general type of $cons$ and
            subsequently verify that the supplied input is some instance of this
            type as in Hindley-Milner, the same expression might be written as:
            
            \begin{minted}{haskell}
              (cons 1 (cons 9 (cons 6 [])))  
            \end{minted}
            
            We can see this difference reflected in the typing rules of the
            systems by way of the following example on \emph{id}:
            
            \[\begin{array}{c@{\qquad}|@{\qquad}c}
                  \mbox{Hindley-Milner}
                  &
                  \mbox{System F}
                  \\
                  id : \forall \alpha \cdot \alpha \to \alpha
                  &
                  id : \Delta \alpha \cdot \alpha \to \alpha
                  \\                  id = \lambda x \cdot x
                  &
                  id = \Lambda t . \lambda x_t \cdot x
            \end{array} \]
            
            The type in the Hindley-Milner system can be proven by:
            
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                    \hypo{x : \alpha \in x : \alpha}   
                  \infer1[var]{x : \alpha \vdash x : \alpha}
                \infer1[abs]{\vdash \lambda x \cdot x : \alpha \to \alpha}
                \hypo{\alpha \notin free(\epsilon)}
               \infer2[gen]{\vdash \lambda x \cdot x : \forall \alpha \cdot
               \alpha \to \alpha}
            \end{prooftree}}
            \end{array} \]
            
            
            The equivalent type in System F can be proven by:
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                  \hypo{x : \alpha \in x : \alpha}
                \infer1[var]{x : \alpha \vdash x : \alpha}
               \infer1[abs]{\vdash \lambda x_t \cdot x : \alpha \to \alpha}
               \infer1[$\Delta$-abs]{\vdash \Lambda t . \lambda x_t \cdot
                 x : \Delta \alpha \cdot \alpha \to \alpha}
            \end{prooftree}}
            \end{array} \]
            
            In system F, this deduces the only type for $\Lambda t . \lambda x_t
            \cdot x$ (up to the renaming of bound variables) however note that
            in Hindley-Milner we may also deduce other type (schemes)
            for $\lambda x \cdot x$: 
            
            \[\begin{array}{c}
            \mbox{\begin{prooftree}
                        \hypo{x : \alpha \to \beta \in x : \alpha \to \beta}
                    \infer1[var]{x : \alpha \to \beta \vdash x : \alpha \to \beta}   
                    \infer1[abs]{\vdash \lambda x \cdot x : (\alpha \to \beta) \to
                    (\alpha \to \beta)}
                    \hypo{\beta \notin free(\epsilon)}        
                \infer2[gen]{\vdash \lambda x \cdot x : \forall \beta \cdot
                  (\alpha \to \beta) \to (\alpha \to \beta)}
                \hypo{\alpha \notin free(\epsilon)}
               \infer2[gen]{\vdash \lambda x \cdot x : \forall \alpha . \forall
                 \beta \cdot (\alpha \to \beta) \to (\alpha \to \beta)}
            \end{prooftree}}
            \end{array} \]
                                   
            If you wanted a term with an equivalent type in system F you would
            need to create a new term $\Lambda t_1 . \Lambda t_2 . \lambda x_{t_1
              \to t_2} \cdot x$
            
            A full list of the typing rules are available in
            appendices \ref{appendix:sysFrules} and
            \ref{appendix:HMrules} respectively. 
                    
          \section{Intuitionistic Type Theory}
        
          Intuitionistic type theory was devised by Per Martin-Löf
          \cite{martinlof1980} originally in the 1970s although he
          later revised the theory many times.

          Martin-Löf was motivated, in part, by what we now call the
          Curry-Howard isomorphism: the idea that statements in logic can be
          thought of as types, and a proof of a logical statement can
          be thought of as a program (consequently simplification of
          proofs correspond to the execution of a program)
          \cite{wadler2015}. He noted that despite this isomorphism,
          computer scientists often developed their own
          languages and type systems instead of using existing
          logics and hence his theory of Intuitionistic types was
          designed to have practical uses as both a logic and
          programming language.

          While the Curry-Howard isomorphism clearly had an existing
          foot hold, relating function types to implication for
          instance, Martin-Löf was the first to extend this to
          predicate logic by having his types depend on values,
          using dependent functions and dependent pairs to represent
          universal and existential quantification respectively.

          It was this introduction of `dependent types` that made this
          theory different from previous type theories and allowing
          the development of dependently typed languages with flexible
          and powerful type systems such as Agda \cite{norell}.

          Although Martin-Löf describes many types in his descriptions
          of this type-system, there are that are of particular
          importance which we will briefly describe here:

          \begin{itemize}
          \item Types of the form $( \Pi x \in A ) B(x)$ describe
            dependent functions, where the type $B(x)$ of the co-domain
            depends on the \emph{value} $x$ of the domain.
          \item Types of the form $( \Sigma x \in A ) B(x)$ describe
            dependent pairs, where the type $B(x)$ of the second
            element of the pair depends on the \emph{value} $x$ of the
            first element.
          \item Type of the form $A + B$ represent the disjoint union
            of two types $A$ and $B$
          \item Types of the form $\mathbb{N}_n$ describe types
            with finite numbers of values. For instance we could take
            $\mathbb{N}_1$ to be unit, $\mathbb{N}_2$ to be booleans
            etc.
          \item Types of the form $I (A , a , b)$ encode propositional
            equality where values of this type represent proofs
            that $a \equiv b \in A$
          \item W-types are a little more complex. They have the form
            $( W x \in A ) B(x)$ and represent \emph{wellorderings} (a
            somewhat more intuitive explanation is that they represent
            well-founded trees). This type allows us to define types
            with complex structures that are inductive in nature. In fact,
            some of the types that Martin-Löf includes in his
            type-theory, such as that of Lists or $\mathbb{N}$ can be
            defined as W-types.
          \item Universes are introduces as a type of types, allowing
            the transfinite types needed to talk about a "sets of
            sets", Martin-Löf recognised the need for such types when
            reasoning about certain areas of maths such as category
            theory \end{itemize}

          One of the consequence of this, more powerful, type system,
          is that unlike Hindley-Milner, we can no longer infer the
          most general type of any expression.

          Take, for example, a value of some dependent pair $(2 , [a :: b
            :: nil])$ perhaps the type of the second element is
          dependent on the first, and the $B$ in the type $(
          \Sigma x \in A ) B(x)$ corresponds to some function $\lambda
          n \to Vec \: X \: n$, and yet maybe it does not depend on the first
          argument at all and $B$ simply corresponds to $\lambda n \to
          Vec \: X \: 2$ - there is no way for us to definitively
          deduce $B$ from the value alone.
  
          \section{Related Work - Research in Progress}

          With these initial readings conducted, time will now be focused on
          further research into areas specific to creating
          type-checkers and their various components. This involves
          some related work that will be partly summarized here but
          many of the readings described have yet not been fully
          consumed.

          \subsection{Contexts and Type Inference}

          Gundry, McBride and McKinna present research detailing an
          novel way of implementing unification and
          type-inference \cite{TypeInferenceInContext}. An area of
          particular interest is in their approach to the
          \emph{context} - traditionally used to track the types of
          term variables.

          In this work, the authors propose a system of explicitly
          tracking type-variables in the context, even before they are
          bound to a type-scheme. As well as allocating types
          to these variables, the unification algorithm is also
          able to pull these type-variables leftward to scope them
          appropriately and solve dependencies while it tries to
          resolve unification constraints.

          This leads to an interesting consequence in their approach to
          generalization in let expressions. Now that type variables
          can exist in the context, we are able to instantiate a type
          scheme by introducing a new type variable to the context,
          and removing the necessary $\forall$ quantifier in the
          scheme. Consequently, to generalize, we can remove these
          type-variables from the context and introduce and
          appropriate $\forall$ quantifier. The authors explicily
          place a third element into the context, a marker that delimits
          generalization to an appropriate scope.

          \subsection{Syntactic Universes}

          More recently, the author has been exploring the concept of
          universe constructions in building a syntactic universe
          where we may build various mechanisms for accomplishing
          static analysis regardless of the underlying syntax of the
          language.

          The concept of a syntactic universe was first introduced by
          the author's supervisor, Conor McBride, and further general
          material on universe constructions was obtained when covered
          as a topic in an Advanced Functional Programming class, taught
          by Fredrik Nordvall Forsberg.

          This idea is explored in a more in-depth context when we
          explore work detailing how we might build a universe of
          syntaxes that are both scope and type safe and abstractly
          define common elements of their semantics such as
          substitution \cite{DBLP:journals/corr/abs-2001-11001}.

          This is an area that is clearly relevant to this authors
          work, although - at the time of writing - progress has still
          to be made by the author in fully understanding the paper.

          \section{Related Work Still To Be Explored}

          There are several other papers to read in the following
          areas of interest:

          \begin{itemize}
          \item An implementation of a dependently typed lambda
            calculus \cite{ATutorialImplementationOfDTLC}
          \item Formalization of bi-directional dependent type systems \cite{TypesWhoSayNi}
          \end{itemize}

          Although there are other less critical papers that the
          author may also tackle if time allows.
       
        \chapter{Project Specification}

          \section{Overview}

          Writing type-checkers for compilers is a key task in the
          development and evolution of programming languages.

          Despite huge variety in the kinds of languages in existence,
          type-systems can often be described using the same kinds of
          things such as typing rules. The descriptions are becoming
          standardized enough for us to recognize common syntax for
          describing these aspects in literature.

          This project seeks to capitalize on this by abstracting
          enough common elements and leaving only what is necessary
          for describing a type-system up to a user. Given any
          description of a type-system in a specified format, a
          type-checker-generator should be able to generate a
          type-checker for the type system.
          
          \section{Goal}

          To design a DSL capable of describing type systems and to
          write a piece of software that, given one of these
          descriptions, is able to type-check code in the language
          it describes.

          \section{Artifacts}

          At a minimum, the finished project will consist of:

          \begin{itemize}
          \item A type-checker generator as a standalone binary
          \item At least one example specification in the DSL
          \item At least two source code examples for each
            specification, one which type-checks successfully and one
            which does not
          \item The final report
          \end{itemize}
          
          \section{Scope}

          \begin{center}
          \begin{tabular}{p{20em}|p{18em}}
            \large In Scope & \large Not In Scope \\ \hline \hline
            Notification on whether the type-checking succeeds
            or fails
            & Detailed feedback from the type-checking process \\ \hline
            Notification on whether or not the specification file is
            successfully parsed
            & Detailed feedback on the parsing of the specification file \\ \hline
            Example specifications and checkable code for small 'toy' languages
            & Example specifications and code for large 'real world' languages \\ \hline
            Single usable feature of 'running' the generator on a
            specification and piece of source code
            & Quality of life / usability features or other niceties \\ \hline
            High level reasoning on why the generated type-checkers
            are likely to be sound and complete
            & Formally proving the generator produces type-checkers
            that are sound and complete\\
          \end{tabular}            
          \end{center}        
          
          \section{Milestones}

          \begin{enumerate}
          \item A DSL that we are able to use to describe existing
            type checkers, used to write \emph{specifications} of type systems.
          \item A type-checker able to check types for a generic syntax
            in a syntactic universe under a \emph{fixed} set of typing rules
            where syntaxes and checkable source code is supplied hard-coded.
          \item A type-checker able to check types when full specifications
            and checkable source code is hard-coded.
          \item A type-checker  that checks types, reading
            the specification and source code from files.
          \end{enumerate}
          
          \section{Acceptance Criteria}

          \begin{itemize}
          \item The software can be ran from the command-line by
            giving a simple command such as: $$\mbox{type-check} \;
            <\emph{specification-file}> \;
            <\emph{source-code-file}>$$
          \item The software either succeeds with a simple indication
            message, or fails with one of two kinds of error:
            \begin{itemize}
            \item Failure to parse specification
            \item Failure to successfully type-check source code
            \end{itemize}
          \item The software passes a fixed set of test cases (specifications and
            source codes) - succeeding, failing and showing
            appropriate errors as detailed in the test cases.
          \item The software can generate type-checkers capable of
            checking both non-dependent and dependent types.
          \end{itemize}
        
        \chapter{Project Plan}

        \section{Objective Timeline}

        The following timeline assigned deadlines to the previously
        identified objectives.
        
        \begin{center}
        \begin{vtimeline}[description={text width=11cm}, 
         row sep=3em]
        16/11/2020 & Complete initial readings on type-theory. \endlr
        30/11/2020 & Complete specific readings relating to the design and
          implementation of various type systems and components thereof.* \endlr
        07/12/2020 & Identify all elements needed to fully and
          unambiguously describe a type system. \endlr
        14/12/2020 & Verify sufficiency of identified elements by fully describing
            two different type systems in the framework. \endlr
        21/12/2020 & Formalize a syntax for expressing these elements. \endlr
        04/01/2021 & Write a specification of a type-checker-generator,
        including identifying areas for verification and/or testing. \endlr
        01/03/2021 & Design and implement a type-checker-generator. \endlr
        15/03/2021 & Verify the implementation according to the
          specification. \endlr
        22/03/2021 & Evaluate the DSL and identify any limitations on the
          kind of type systems that it can represent. \endlr
        \end{vtimeline}          
        \end{center}
        * This is the target date of completion for \emph{currently planned}
        readings only
        
        \section{Current Progress}

          \subsection{Areas of action}
        
          Initial readings on general type-theories have been
          completed and more specific in-depth readings on relevant
          topics are currently underway.

          As an exercise, a previously presented unification algorithm
          \cite{TypeInferenceInContext} has been adapted and
          re-written in Agda (the author's implementation language of
          choice).

          Writing has begun on various sections of the final report,
          including a review of the literature, somewhat similar to
          the "Related Work" section in this report.

          Some coding exercise have been conducted exploring the
          concept of using universe constructions to program generically.
        
          \subsection{Areas of thought}

          After reading about the idea of storing type-variables
          explicitly in the context \cite{TypeInferenceInContext} more
          thought is being given to how to best utilize this technique
          in this project.
          
          Given that the context is such a ubiquitous notion in
          type-theories, it is likely that the idea of being
          explicit about type-variables has uses outwith
          Hindley-Milner and this is an area that this author will explore
          further. This paper also details relevant unification and type
          inference algorithms that could be helpful in the
          development of a type-checker generator, should it be
          possible to abstract the algorithms over a universe of
          syntaxes and associated typing rules. Thought in this area
          is an ongoing process.

          Thought is also being given to the concept of syntactic
          universes. It is clear that this idea allows us to create
          our software generalizing over the kinds of syntax to which it
          will be applied. However the author would like to gain a
          deeper understanding about how best to design a syntactic
          universe. In the context of this project, how might one
          choose a sensible abstraction? What qualities should our
          universe have? What level of detail do we require, and thus
          force on our end user to specify? Do we need to give
          special consideration if we are putting the onus on a user
          to 'wire up' a syntax to our syntactic generalization?
          
        \chapter{The Development Process}
        \section{Development Methodology}

        In this project, although the primary goal is the production
        of software, much of the work is theoretical in nature. With
        that in mind, it is proposed to split the project in three:
        initial theoretical work (such as formalizing a language to
        describe type systems), the design and implementation of the
        type-checker-generator (the software development element) and
        the verification of the software (again somewhat theoretical
        in nature where we look at soundness and completeness).
        
        In the development phase of the project, an agile approach to
        development will be employed. 

        The author will take a Scrum-style approach to the development
        process, adapting the usual teamwork-focused elements to be
        more suited to a single developer environment.

        Of the four identified milestones, the last three of these
        will make up the epics under this system, where these will be
        broken down into more granular tickets for each sprint.

        The development section of the project has been allocated 8
        weeks, this will be split into four sprints each lasting two
        weeks. 
        
        \section{Design}

        As we are working within a scrum-style agile framework, the
        design will take place in small increments within each
        sprint.

        As we are working in a functional language, there are many
        prevalent concepts that, although present in design literature
        in general, are not as relevant in this context. For
        instance, object-oriented programming places an emphasis on
        the concepts of "design patterns", this is a concept discussed
        far less with regards to functional programming - some might
        argue because it is a more efficient paradigm that does not
        require them, others might argue that their use is implicit.

        One area of particular interest to the author is type driven
        design - where much of the type information is filled in
        first, and the implementation details often follow
        afterward. This style of development could aid us in making
        better use of Agda's dependent type system.

        It is hoped that with careful consideration of types, the
        author might identify areas to better verify correctness of
        implementing code by introducing invariants that guarantee desirable
        properties and reduce the number of possible incorrect
        implementations - although this is an area of research in its
        own right and is certainly not the focus of this project.
        
        \section{Testing/Verification}

        The testing and verification process is multi-faceted in
        nature.

        It is the aim of this project to utilize the type system in
        order to help verify correctness at the level of component
        functions (as described when discussing type-driven design
        previously).

        In addition, high level test cases (in other paradigms
        referred to as integration tests) will be conducted by
        supplying example source code to the type-checker where the
        expected outcome is known in advance. Clearly these examples
        will be small in nature as the the expected outcome needs to
        be calculated by hand.

        Finally, we aim to explore the likelihood that generated
        type-checkers are sound and complete by reasoning about our
        software. 
        	
	\input{appendices.tex}
	
	\clearpage
	\addcontentsline{toc}{chapter}{Bibliography}
	\printbibliography
	\nocite{*} % temporarily until I know what I'm using
\end{document}
