\chapter{Relevant related work}

In the previous chapter, we explored material designed to give a
general background of type-theory. Here we will explore some more
modern works which will help us in the construction of a
type-checker-generator.

\section{Contexts and type inference}

Gundry, McBride and McKinna present research detailing an
novel way of implementing unification and
type-inference \cite{TypeInferenceInContext}. An area of
particular interest is in their approach to the
\emph{context} - traditionally used to track the types of
term variables.

In this work, the authors propose a system of explicitly
tracking type-variables in the context, even before they are
bound to a type-scheme. As well as allocating types
to these variables, the unification algorithm is also
able to pull these type-variables leftward to scope them
appropriately and resolve dependencies, while it tries to
solve unification constraints.

This leads to an interesting consequence in their approach to
generalization in let expressions. Now that type variables
can exist in the context, we are able to instantiate a type
scheme by introducing a new type variable to the context,
and removing the necessary $\forall$ quantifier in the
scheme. Consequently, to generalize, we can remove these
type-variables from the context and introduce and
appropriate $\forall$ quantifier. The authors explicily
place a third element into the context, a marker that delimits
generalization to an appropriate scope.

\section{Syntactic universes}

The concept of a syntactic universe was first introduced by
the author's supervisor, Conor McBride, and further general
material on universe constructions was obtained when covered
as a topic in an Advanced Functional Programming class, taught
by Fredrik Nordvall Forsberg.

Universe constructions are a way of programming generically by
computing over descriptions of data, rather than the data itself. Thus
we design descriptions carefully to capture the properties of
everything in our universe, create the required computations on the
descriptions, and couple this with the ability to create descriptions
and retrieve the \emph{meaning} of descriptions - get ahold of
the actual entity they are describing.

This idea is explored in more depth when we
explore work detailing how we might build a universe of
syntaxes that are both scope and type safe and abstractly
define common semantics such as substitution (which is defined in this
paper to work over arbitrary descriptions) and type-checking (which is
defined in this paper to work over a specific description only).
\cite{DBLP:journals/corr/abs-2001-11001}.

In this paper, the authors detail a universe of type and scope safe
syntaxes. First they formalise the concept of well scoped entities by
way of a family of types and provide useful combinators and the required machinery
for representing environments. They also introduce the idea of a
generic notion of semanitics for a language and demonstrate its use by
defining several operations in terms of this generic semantics.

After priming the reader on previous work in creating a universe of
data types \cite{DBLP:conf/icfp/ChapmanDMM10} they then go on to
modify the \emph{descriptions} defined in this work in order to be instead
describe a universe of scope safe and well-kinded syntaxes.

With this concept of descriptions in place, the previous notion of
semantics is replaced by a more generic notion which is not
syntax-specific and can be used to represent a semantics for any
language that we might \emph{describe}. With these mechanics
in place they are able to show true syntax-generic programming by
forming functionality as semantics over a generic description.

Later in this paper, the authors broach the subject of type-checking
and elaboration. In particular, their section on elaboration provides
a concrete example of creating an elaborator as a semantics over a
description of bidirectional lambda calculus.

\section{Bi-directional dependent type theory}

While bi-directional typing is not new
\cite{DBLP:journals/toplas/PierceT00}, formalization of the metatheory
is \cite{TypesWhoSayNi}. 

The work in this paper formalizes the metatheory for a whole class of
bi-directional dependently typed languages. It demonstrates how
desirable properties of type systems may be enforced by construction,
outlines pitfalls that might be encountered when combining type
checking with type synthesis, and provides an object-level
syntax split into carefully chosen grammatical classes that we might
use to represent arbitrary syntax.

It then emphasises the importance of precisely tracking information
flow as it defines judgement forms, patterns, expressions and typing
rules and determines a method for approaching the \emph{schematic
  variables} that appear in \emph{formal judgements} in the typing
rules.

It is from this work we notice that by paying
careful attention to the construction the individual components used to
describe a type theory, we may minimize the amount of information
the user is required to give, and better validate the information that
they do give to ensure the resulting system has desirable
properties. It also provides a useful framework for approaching
this project as a whole.

